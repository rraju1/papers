# Intriguing properties of neural networks

This is a very important paper because it is the one that introduces the notion of adverserial examples in ML.

There are 2 claims made in the abstract:
  1. There is no distinction between individual high level units and random linear combinations of high level units.
  2. Neural nets are discontinous in their mapping and adverserial examples exist to misclassify the network by perturbing the input slightly at an imperceptible level.
  


Slides on Bo Li's website: [Slides](http://nebula.wsimg.com/3b1c9dcbb65e2367da1d1ad685a8360b?AccessKeyId=619655DB521D0ED197FE&disposition=0&alloworigin=1)

https://arxiv.org/pdf/1312.6199.pdf
